{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cleaner.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9RyVkMQTELB"
      },
      "source": [
        "Import relevant packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVXfrsUmTCT_"
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "OG7liUQAaQ2O",
        "outputId": "6b102802-4eb0-4543-bcd6-9634904f1a53"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/Lassenoerre/datascience/master/datasets/articles_0_6000.csv?token=ARZVGJ34RODPQRSDIMC6LAC7XE3II', header=0, names=['Title', 'Topic', 'Date', 'Content', 'URL'], usecols=[1,2,3,4,5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8fe54770d373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/Lassenoerre/datascience/master/datasets/articles_0_6000.csv?token=ARZVGJ34RODPQRSDIMC6LAC7XE3II'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Topic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'URL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "kOeoqD4_bMLW",
        "outputId": "7d2987c6-57eb-4f97-a543-adea262f052f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Date</th>\n",
              "      <th>Content</th>\n",
              "      <th>URL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Shopping Malls Tracking Holiday Sales</td>\n",
              "      <td>Street Signs</td>\n",
              "      <td>27-11-2006</td>\n",
              "      <td>Its not only retailers who are closely watchin...</td>\n",
              "      <td>https://www.cnbc.com/2006/11/27/shopping-malls...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Consumers Adore Gift Cards</td>\n",
              "      <td>U.S. News</td>\n",
              "      <td>27-11-2006</td>\n",
              "      <td>The National Retail Federation\\xe2\\x80\\x99s Ho...</td>\n",
              "      <td>https://www.cnbc.com/2006/11/27/consumers-ador...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What's Wrong With Wal-Mart?</td>\n",
              "      <td>Street Signs</td>\n",
              "      <td>27-11-2006</td>\n",
              "      <td>Despite the fine weather in much of the nation...</td>\n",
              "      <td>https://www.cnbc.com/2006/11/27/whats-wrong-wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Shape Up, Ship Out</td>\n",
              "      <td>Holiday Central</td>\n",
              "      <td>27-11-2006</td>\n",
              "      <td>It helped nail the coffin shut on eToys. It\\xe...</td>\n",
              "      <td>https://www.cnbc.com/2006/11/27/shape-up-ship-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Big Box Boom: Gadgets Sell \\xe2\\x80\\x93 And Pr...</td>\n",
              "      <td>Holiday Central</td>\n",
              "      <td>27-11-2006</td>\n",
              "      <td>There\\xe2\\x80\\x99s plenty of time to shop for ...</td>\n",
              "      <td>https://www.cnbc.com/2006/11/27/big-box-boom-g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                                URL\n",
              "0              Shopping Malls Tracking Holiday Sales  ...  https://www.cnbc.com/2006/11/27/shopping-malls...\n",
              "1                        Consumers Adore Gift Cards   ...  https://www.cnbc.com/2006/11/27/consumers-ador...\n",
              "2                        What's Wrong With Wal-Mart?  ...  https://www.cnbc.com/2006/11/27/whats-wrong-wi...\n",
              "3                                 Shape Up, Ship Out  ...  https://www.cnbc.com/2006/11/27/shape-up-ship-...\n",
              "4  Big Box Boom: Gadgets Sell \\xe2\\x80\\x93 And Pr...  ...  https://www.cnbc.com/2006/11/27/big-box-boom-g...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpYRQLXLydwg"
      },
      "source": [
        "Convert all article content to stringe type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7jyD2MteVak"
      },
      "source": [
        "df['Content'] = df['Content'].astype('str')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NmHXyLfy5aw"
      },
      "source": [
        "Replace all article content with the title if the title is longer than the article content: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04jQFvZIpUs5"
      },
      "source": [
        "for index in df.index:\n",
        "  if len(df['Content'][index]) < len(df['Title'][index]):\n",
        "    df['Content'][index]=df['Title'][index]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLIwvgKTTRzh"
      },
      "source": [
        "Define a function to remove special unicode characters and other non-relevant N-grams from each article:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSit01rETd1Y"
      },
      "source": [
        "def remove_clutter(text):\n",
        "\n",
        "    #Trying to remove special unicode characters\n",
        "    #text = re.sub(r'\\\\x[A-Za-z0-9_]{2}', '', text)\n",
        "    \n",
        "    #Trying to remove video annotation\n",
        "    text = re.sub(r'VIDEO([0-9]|[0-9]{2}):[0-9]{4}:[0-9]{2}', ' ', text)\n",
        "\n",
        "    # Remove unicode characters:\n",
        "    text = ''.join([x for x in text if ord(x) < 127])\n",
        "    \n",
        "    # Remove all \"â\" with space:\n",
        "    text = re.sub(r'â',' ', text)\n",
        "    text = re.sub(r'Â',' ', text)\n",
        "    \n",
        "    # Remove all \"Getty images\":\n",
        "    text = re.sub(r'getty imgages','', text) \n",
        "\n",
        "    # Remove all double-spaces:\n",
        "    text = re.sub(r'  ',' ', text)\n",
        "\n",
        "    # Remove commas:\n",
        "    text = re.sub(r',','', text)\n",
        "\n",
        "    # Replace abbrevations:\n",
        "    text = re.sub(r\"don't\",\"donnot\", text)\n",
        "    text = re.sub(r\"can't\",\"cannot\", text)\n",
        "    text = re.sub(r\"weren't\",\"werent\", text)\n",
        "    text = re.sub(r\"couldn't\",\"couldnt\", text)\n",
        "    text = re.sub(r\"doesn't\",\"doesnot\", text)\n",
        "    text = re.sub(r\"didn't\",\"didnot\", text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WibnqLTp7l"
      },
      "source": [
        "Load the English language model instance in spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSFYOvRdTpfK"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs-y6HrzUPXv"
      },
      "source": [
        "Define a function to clean all our articles in a specific column in a dataset and return the tokenized data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isbwqt0VUTx4"
      },
      "source": [
        "def cleaning(df,column):\n",
        "    \n",
        "    # Create an empty list to store tokens:\n",
        "    tokens = []\n",
        "\n",
        "    # Apply the remove_clutter function on all articles in the df:\n",
        "    df[column].apply(remove_clutter)\n",
        "\n",
        "    # Define an object to count the progress:\n",
        "\n",
        "    count = 0\n",
        "    \n",
        "    # Iterate over all articles in the dataframe and create a nlp object for each:\n",
        "    for article in nlp.pipe(df[column], disable=[\"parser\"]):\n",
        "        \n",
        "        # Store all cleaned tokens in a list using list comprehension:\n",
        "        article_tok = [token.lemma_.lower() for token in article if token.is_alpha and not token.is_stop and token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'ADV', 'VERB'] and token.ent_type_ not in ['PERSON', 'MONEY', 'PERCENT', 'LOC', 'DATE', 'TIME', 'QUANTITY', 'ORDINAL'] and len(token)>1]\n",
        "        \n",
        "        # Insert list of tokens into the list \"tokens\":\n",
        "        tokens.append(article_tok)\n",
        "\n",
        "        # Print the progress:\n",
        "        print(f'processed {count}/{len(df[column])}')\n",
        "        \n",
        "    # Insert a column in the dataframe with all tokens for each article:\n",
        "    df['tokens'] = tokens\n",
        "    \n",
        "    # Insert tokens as a string in a new column in the dataframe:\n",
        "    df[\"clean_articles\"] = df[\"tokens\"].map(lambda row: \" \".join(row))\n",
        "\n",
        "    # Return the df\n",
        "    return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTSZJ5d7UtCw"
      },
      "source": [
        "Call the cleaning function on the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "cjUSjm71Uu_o",
        "outputId": "8e1c6434-1314-4b29-fbfc-249def4b4496"
      },
      "source": [
        "cleaning(df,'Content')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-899569e48b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgaWVxIBUx4S"
      },
      "source": [
        "Example: How to entity recognition work:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S6DEVE7xoKil",
        "outputId": "36a441f7-938d-459f-dee8-04528949875e"
      },
      "source": [
        "df['URL'][5167]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://www.cnbc.com/2007/06/06/prudential-shuts-down-stock-research-trading-arm.html'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9U88Q2lXmn1"
      },
      "source": [
        "doc = nlp(\"don't\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev5dBbtHsJ_i",
        "outputId": "4cbb9285-497d-4b18-d423-d5bc8e0cc958"
      },
      "source": [
        "for tok in doc:\n",
        "  print(tok)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "do\n",
            "n't\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H1CIPugV9zM"
      },
      "source": [
        "sentence_spans = list(doc.sents)\n",
        "displacy.serve(sentence_spans, style=\"dep\")\n",
        "\n",
        "displacy.serve(doc, style=\"dep\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKJyCg0oUxMg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}