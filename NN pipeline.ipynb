{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('articles_all_clean.csv')\n",
    "df = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Link</th>\n",
       "      <th>tokens</th>\n",
       "      <th>clean_articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Shopping Malls Tracking Holiday Sales</td>\n",
       "      <td>Street Signs</td>\n",
       "      <td>27-11-2006</td>\n",
       "      <td>Its not only retailers who are closely watchin...</td>\n",
       "      <td>https://www.cnbc.com/2006/11/27/shopping-malls...</td>\n",
       "      <td>['retailer', 'closely', 'watch', 'holiday', 'r...</td>\n",
       "      <td>retailer closely watch holiday receipt mall ow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Consumers Adore Gift Cards</td>\n",
       "      <td>U.S. News</td>\n",
       "      <td>27-11-2006</td>\n",
       "      <td>The National Retail Federations Holiday Consum...</td>\n",
       "      <td>https://www.cnbc.com/2006/11/27/consumers-ador...</td>\n",
       "      <td>['national', 'retail', 'federations', 'holiday...</td>\n",
       "      <td>national retail federations holiday consumer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Whats Wrong With Wal-Mart?</td>\n",
       "      <td>Street Signs</td>\n",
       "      <td>27-11-2006</td>\n",
       "      <td>Despite the fine weather in much of the nation...</td>\n",
       "      <td>https://www.cnbc.com/2006/11/27/whats-wrong-wi...</td>\n",
       "      <td>['fine', 'weather', 'nation', 'large', 'retail...</td>\n",
       "      <td>fine weather nation large retailer dark cloud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Shape Up Ship Out</td>\n",
       "      <td>Holiday Central</td>\n",
       "      <td>27-11-2006</td>\n",
       "      <td>It helped nail the coffin shut on eToys. Its t...</td>\n",
       "      <td>https://www.cnbc.com/2006/11/27/shape-up-ship-...</td>\n",
       "      <td>['help', 'nail', 'coffin', 'shut', 'etoys', 'g...</td>\n",
       "      <td>help nail coffin shut etoys great equalizer br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Big Box Boom: Gadgets Sell And Prices Boil</td>\n",
       "      <td>Holiday Central</td>\n",
       "      <td>27-11-2006</td>\n",
       "      <td>Theres plenty of time to shop for Christmas ri...</td>\n",
       "      <td>https://www.cnbc.com/2006/11/27/big-box-boom-g...</td>\n",
       "      <td>['plenty', 'time', 'shop', 'caveat', 'procrast...</td>\n",
       "      <td>plenty time shop caveat procrastinator flat sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       Title            Topic  \\\n",
       "0           0       Shopping Malls Tracking Holiday Sales     Street Signs   \n",
       "1           1                 Consumers Adore Gift Cards         U.S. News   \n",
       "2           2                  Whats Wrong With Wal-Mart?     Street Signs   \n",
       "3           3                           Shape Up Ship Out  Holiday Central   \n",
       "4           4  Big Box Boom: Gadgets Sell And Prices Boil  Holiday Central   \n",
       "\n",
       "         Date                                            Content  \\\n",
       "0  27-11-2006  Its not only retailers who are closely watchin...   \n",
       "1  27-11-2006  The National Retail Federations Holiday Consum...   \n",
       "2  27-11-2006  Despite the fine weather in much of the nation...   \n",
       "3  27-11-2006  It helped nail the coffin shut on eToys. Its t...   \n",
       "4  27-11-2006  Theres plenty of time to shop for Christmas ri...   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.cnbc.com/2006/11/27/shopping-malls...   \n",
       "1  https://www.cnbc.com/2006/11/27/consumers-ador...   \n",
       "2  https://www.cnbc.com/2006/11/27/whats-wrong-wi...   \n",
       "3  https://www.cnbc.com/2006/11/27/shape-up-ship-...   \n",
       "4  https://www.cnbc.com/2006/11/27/big-box-boom-g...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['retailer', 'closely', 'watch', 'holiday', 'r...   \n",
       "1  ['national', 'retail', 'federations', 'holiday...   \n",
       "2  ['fine', 'weather', 'nation', 'large', 'retail...   \n",
       "3  ['help', 'nail', 'coffin', 'shut', 'etoys', 'g...   \n",
       "4  ['plenty', 'time', 'shop', 'caveat', 'procrast...   \n",
       "\n",
       "                                      clean_articles  \n",
       "0  retailer closely watch holiday receipt mall ow...  \n",
       "1  national retail federations holiday consumer i...  \n",
       "2  fine weather nation large retailer dark cloud ...  \n",
       "3  help nail coffin shut etoys great equalizer br...  \n",
       "4  plenty time shop caveat procrastinator flat sc...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define x and y variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 4, 1, 1, 3, 3, 3, 2, 1, 2, 4, 2, 1, 2, 5, 4, 5, 4, 3, 4, 3, 2, 2, 4, 2, 4, 5, 1, 5, 3, 1, 1, 2, 3, 2, 5, 1, 5, 2, 3, 2, 2, 4, 4, 5, 5, 3, 3, 5, 5, 3, 1, 3, 5, 1, 4, 3, 2, 2, 5, 5, 1, 2, 5, 1, 1, 4, 2, 5, 5, 3, 4, 1, 1, 5, 1, 2, 5, 5, 2, 2, 5, 5, 4, 1, 5, 5, 3, 2, 4, 2, 5, 2, 5, 2, 4, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['y'] = np.random.randint(1, 6, df.shape[0])\n",
    "labels = df['y'].astype('float32').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define x by converting the column with article tokens to a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = df[\"clean_articles\"].astype('str').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs for the Embedding Layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the vocabulary size to the number of tokens in our vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "#num_words = vocab_size\n",
    "tokenizer.fit_on_texts(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'say',\n",
       " 2: 'sale',\n",
       " 3: 'market',\n",
       " 4: 'price',\n",
       " 5: 'high',\n",
       " 6: 'report',\n",
       " 7: 'expect',\n",
       " 8: 'rise',\n",
       " 9: 'rate',\n",
       " 10: 'company',\n",
       " 11: 'fall',\n",
       " 12: 'share',\n",
       " 13: 'home',\n",
       " 14: 'store',\n",
       " 15: 'new',\n",
       " 16: 'low',\n",
       " 17: 'stock',\n",
       " 18: 'economic',\n",
       " 19: 'growth',\n",
       " 20: 'consumer',\n",
       " 21: 'analyst',\n",
       " 22: 'close',\n",
       " 23: 'economy',\n",
       " 24: 'housing',\n",
       " 25: 'oil',\n",
       " 26: 'inflation',\n",
       " 27: 'fed',\n",
       " 28: 'business',\n",
       " 29: 'cut',\n",
       " 30: 'good',\n",
       " 31: 'datum',\n",
       " 32: 'big',\n",
       " 33: 'decline',\n",
       " 34: 'large',\n",
       " 35: 'time',\n",
       " 36: 'sell',\n",
       " 37: 'tell',\n",
       " 38: 'gain',\n",
       " 39: 'increase',\n",
       " 40: 'look',\n",
       " 41: 'drop',\n",
       " 42: 'forecast',\n",
       " 43: 'street',\n",
       " 44: 'buy',\n",
       " 45: 'investment',\n",
       " 46: 'spending',\n",
       " 47: 'estimate',\n",
       " 48: 'interest',\n",
       " 49: 'remain',\n",
       " 50: 'come',\n",
       " 51: 'bank',\n",
       " 52: 'strong',\n",
       " 53: 'group',\n",
       " 54: 'wal',\n",
       " 55: 'see',\n",
       " 56: 'point',\n",
       " 57: 'cnbcs',\n",
       " 58: 'dollar',\n",
       " 59: 'york',\n",
       " 60: 'chief',\n",
       " 61: 'retailer',\n",
       " 62: 'accord',\n",
       " 63: 'sector',\n",
       " 64: 'help',\n",
       " 65: 'number',\n",
       " 66: 'department',\n",
       " 67: 'federal',\n",
       " 68: 'deal',\n",
       " 69: 'index',\n",
       " 70: 'reserve',\n",
       " 71: 'chairman',\n",
       " 72: 'average',\n",
       " 73: 'retail',\n",
       " 74: 'level',\n",
       " 75: 'power',\n",
       " 76: 'energy',\n",
       " 77: 'product',\n",
       " 78: 'wall',\n",
       " 79: 'investor',\n",
       " 80: 'cost',\n",
       " 81: 'comment',\n",
       " 82: 'economist',\n",
       " 83: 'go',\n",
       " 84: 'slow',\n",
       " 85: 'weak',\n",
       " 86: 'demand',\n",
       " 87: 'grow',\n",
       " 88: 'holiday',\n",
       " 89: 'show',\n",
       " 90: 'world',\n",
       " 91: 'think',\n",
       " 92: 'figure',\n",
       " 93: 'firm',\n",
       " 94: 'people',\n",
       " 95: 'mart',\n",
       " 96: 'crude',\n",
       " 97: 'open',\n",
       " 98: 'continue',\n",
       " 99: 'offer',\n",
       " 100: 'include',\n",
       " 101: 'likely',\n",
       " 102: 'dolor',\n",
       " 103: 'story',\n",
       " 104: 'slightly',\n",
       " 105: 'earning',\n",
       " 106: 'watch',\n",
       " 107: 'activity',\n",
       " 108: 'news',\n",
       " 109: 'give',\n",
       " 110: 'expectation',\n",
       " 111: 'add',\n",
       " 112: 'trade',\n",
       " 113: 'spend',\n",
       " 114: 'order',\n",
       " 115: 'note',\n",
       " 116: 'financial',\n",
       " 117: 'capital',\n",
       " 118: 'fan',\n",
       " 119: 'national',\n",
       " 120: 'list',\n",
       " 121: 'positive',\n",
       " 122: 'impact',\n",
       " 123: 'have',\n",
       " 124: 'overall',\n",
       " 125: 'moderate',\n",
       " 126: 'profit',\n",
       " 127: 'gm',\n",
       " 128: 'cnbc',\n",
       " 129: 'little',\n",
       " 130: 'hit',\n",
       " 131: 'take',\n",
       " 132: 'lead',\n",
       " 133: 'future',\n",
       " 134: 'ahead',\n",
       " 135: 'bad',\n",
       " 136: 'start',\n",
       " 137: 'revenue',\n",
       " 138: 'end',\n",
       " 139: 'pace',\n",
       " 140: 'sport',\n",
       " 141: 'raise',\n",
       " 142: 'line',\n",
       " 143: 'make',\n",
       " 144: 'get',\n",
       " 145: 'inventory',\n",
       " 146: 'sign',\n",
       " 147: 'believe',\n",
       " 148: 'way',\n",
       " 149: 'question',\n",
       " 150: 'result',\n",
       " 151: 'hope',\n",
       " 152: 'major',\n",
       " 153: 'value',\n",
       " 154: 'base',\n",
       " 155: 'gasoline',\n",
       " 156: 'industry',\n",
       " 157: 'survey',\n",
       " 158: 'great',\n",
       " 159: 'box',\n",
       " 160: 'late',\n",
       " 161: 'concern',\n",
       " 162: 'well',\n",
       " 163: 'income',\n",
       " 164: 'lunch',\n",
       " 165: 'post',\n",
       " 166: 'morning',\n",
       " 167: 'core',\n",
       " 168: 'release',\n",
       " 169: 'labor',\n",
       " 170: 'operation',\n",
       " 171: 'need',\n",
       " 172: 'turpis',\n",
       " 173: 'tortor',\n",
       " 174: 'eu',\n",
       " 175: 'purus',\n",
       " 176: 'varius',\n",
       " 177: 'tempus',\n",
       " 178: 'tempor',\n",
       " 179: 'diamfaucibus',\n",
       " 180: 'pulvinar',\n",
       " 181: 'speak',\n",
       " 182: 'president',\n",
       " 183: 'card',\n",
       " 184: 'find',\n",
       " 185: 'tv',\n",
       " 186: 'run',\n",
       " 187: 'meet',\n",
       " 188: 'trading',\n",
       " 189: 'long',\n",
       " 190: 'term',\n",
       " 191: 'plan',\n",
       " 192: 'real',\n",
       " 193: 'book',\n",
       " 194: 'slump',\n",
       " 195: 'dow',\n",
       " 196: 'target',\n",
       " 197: 'provide',\n",
       " 198: 'loss',\n",
       " 199: 'maker',\n",
       " 200: 'bid',\n",
       " 201: 'credit',\n",
       " 202: 'house',\n",
       " 203: 'know',\n",
       " 204: 'gift',\n",
       " 205: 'record',\n",
       " 206: 'compare',\n",
       " 207: 'weather',\n",
       " 208: 'service',\n",
       " 209: 'will',\n",
       " 210: 'flat',\n",
       " 211: 'set',\n",
       " 212: 'hold',\n",
       " 213: 'meeting',\n",
       " 214: 'appear',\n",
       " 215: 'follow',\n",
       " 216: 'private',\n",
       " 217: 'sharply',\n",
       " 218: 'predict',\n",
       " 219: 'food',\n",
       " 220: 'pccw',\n",
       " 221: 'electronic',\n",
       " 222: 'weakness',\n",
       " 223: 'shopping',\n",
       " 224: 'game',\n",
       " 225: 'united',\n",
       " 226: 'opec',\n",
       " 227: 'support',\n",
       " 228: 'euro',\n",
       " 229: 'half',\n",
       " 230: 'break',\n",
       " 231: 'early',\n",
       " 232: 'director',\n",
       " 233: 'government',\n",
       " 234: 'drag',\n",
       " 235: 'bernanke',\n",
       " 236: 'slowdown',\n",
       " 237: 'risk',\n",
       " 238: 'beige',\n",
       " 239: 'exchange',\n",
       " 240: 'ford',\n",
       " 241: 'motor',\n",
       " 242: 'states',\n",
       " 243: 'shareholder',\n",
       " 244: 'auto',\n",
       " 245: 'trend',\n",
       " 246: 'period',\n",
       " 247: 'hybrid',\n",
       " 248: 'gdp',\n",
       " 249: 'phone',\n",
       " 250: 'poll',\n",
       " 251: 'online',\n",
       " 252: 'squawk',\n",
       " 253: 'barrel',\n",
       " 254: 'measure',\n",
       " 255: 'fuel',\n",
       " 256: 'policy',\n",
       " 257: 'senior',\n",
       " 258: 'especially',\n",
       " 259: 'executive',\n",
       " 260: 'video',\n",
       " 261: 'detail',\n",
       " 262: 'outlook',\n",
       " 263: 'mixed',\n",
       " 264: 'expand',\n",
       " 265: 'move',\n",
       " 266: 'commerce',\n",
       " 267: 'region',\n",
       " 268: 'exist',\n",
       " 269: 'hong',\n",
       " 270: 'global',\n",
       " 271: 'worth',\n",
       " 272: 'automaker',\n",
       " 273: 'european',\n",
       " 274: 'speech',\n",
       " 275: 'mortgage',\n",
       " 276: 'control',\n",
       " 277: 'closely',\n",
       " 278: 'nation',\n",
       " 279: 'year',\n",
       " 280: 'agree',\n",
       " 281: 'margin',\n",
       " 282: 'call',\n",
       " 283: 'area',\n",
       " 284: 'boost',\n",
       " 285: 'producer',\n",
       " 286: 'read',\n",
       " 287: 'production',\n",
       " 288: 'supply',\n",
       " 289: 'marts',\n",
       " 290: 'sony',\n",
       " 291: 'brand',\n",
       " 292: 'work',\n",
       " 293: 'pressure',\n",
       " 294: 'session',\n",
       " 295: 'lift',\n",
       " 296: 'reflect',\n",
       " 297: 'domestic',\n",
       " 298: 'air',\n",
       " 299: 'stake',\n",
       " 300: 'talk',\n",
       " 301: 'jersey',\n",
       " 302: 'equity',\n",
       " 303: 'issue',\n",
       " 304: 'want',\n",
       " 305: 'improve',\n",
       " 306: 'construction',\n",
       " 307: 'lose',\n",
       " 308: 'indicate',\n",
       " 309: 'meat',\n",
       " 310: 'general',\n",
       " 311: 'association',\n",
       " 312: 'closing',\n",
       " 313: 'fund',\n",
       " 314: 'turn',\n",
       " 315: 'research',\n",
       " 316: 'reach',\n",
       " 317: 'screen',\n",
       " 318: 'higher',\n",
       " 319: 'probably',\n",
       " 320: 'cite',\n",
       " 321: 'luxury',\n",
       " 322: 'strategist',\n",
       " 323: 'leave',\n",
       " 324: 'pay',\n",
       " 325: 'benefit',\n",
       " 326: 'industrial',\n",
       " 327: 'nasdaq',\n",
       " 328: 'technology',\n",
       " 329: 'confidence',\n",
       " 330: 'board',\n",
       " 331: 'gross',\n",
       " 332: 'distillate',\n",
       " 333: 'estate',\n",
       " 334: 'pfizer',\n",
       " 335: 'soft',\n",
       " 336: 'cool',\n",
       " 337: 'cover',\n",
       " 338: 'source',\n",
       " 339: 'vehicle',\n",
       " 340: 'japanese',\n",
       " 341: 'japan',\n",
       " 342: 'total',\n",
       " 343: 'district',\n",
       " 344: 'america',\n",
       " 345: 'strength',\n",
       " 346: 'thomson',\n",
       " 347: 'sit',\n",
       " 348: 'city',\n",
       " 349: 'bell',\n",
       " 350: 'interview',\n",
       " 351: 'gas',\n",
       " 352: 'opportunity',\n",
       " 353: 'digital',\n",
       " 354: 'shopper',\n",
       " 355: 'review',\n",
       " 356: 'winner',\n",
       " 357: 'site',\n",
       " 358: 'toy',\n",
       " 359: 'worry',\n",
       " 360: 'bring',\n",
       " 361: 'bullish',\n",
       " 362: 'central',\n",
       " 363: 'factor',\n",
       " 364: 'tiffany',\n",
       " 365: 'far',\n",
       " 366: 'hard',\n",
       " 367: 'short',\n",
       " 368: 'keep',\n",
       " 369: 'case',\n",
       " 370: 'money',\n",
       " 371: 'stay',\n",
       " 372: 'play',\n",
       " 373: 'state',\n",
       " 374: 'jones',\n",
       " 375: 'key',\n",
       " 376: 'durable',\n",
       " 377: 'stores',\n",
       " 378: 'commercial',\n",
       " 379: 'lower',\n",
       " 380: 'fast',\n",
       " 381: 'median',\n",
       " 382: 'feds',\n",
       " 383: 'plunge',\n",
       " 384: 'reuters',\n",
       " 385: 'filing',\n",
       " 386: 'green',\n",
       " 387: 'struggle',\n",
       " 388: 'output',\n",
       " 389: 'cold',\n",
       " 390: 'committee',\n",
       " 391: 'overseas',\n",
       " 392: 'able',\n",
       " 393: 'statement',\n",
       " 394: 'solid',\n",
       " 395: 'job',\n",
       " 396: 'ease',\n",
       " 397: 'regulatory',\n",
       " 398: 'net',\n",
       " 399: 'focus',\n",
       " 400: 'competition',\n",
       " 401: 'improvement',\n",
       " 402: 'beat',\n",
       " 403: 'hike',\n",
       " 404: 'corporate',\n",
       " 405: 'ipsum',\n",
       " 406: 'amet',\n",
       " 407: 'consectetur',\n",
       " 408: 'adipisce',\n",
       " 409: 'elit',\n",
       " 410: 'malesuada',\n",
       " 411: 'ut',\n",
       " 412: 'posuere',\n",
       " 413: 'dapi',\n",
       " 414: 'suscipit',\n",
       " 415: 'owner',\n",
       " 416: 'today',\n",
       " 417: 'man',\n",
       " 418: 'favorite',\n",
       " 419: 'ticket',\n",
       " 420: 'fine',\n",
       " 421: 'miss',\n",
       " 422: 'face',\n",
       " 423: 'shop',\n",
       " 424: 'unit',\n",
       " 425: 'boom',\n",
       " 426: 'hand',\n",
       " 427: 'course',\n",
       " 428: 'commodity',\n",
       " 429: 'push',\n",
       " 430: 'day',\n",
       " 431: 'decide',\n",
       " 432: 'aim',\n",
       " 433: 'climb',\n",
       " 434: 'nearly',\n",
       " 435: 'discount',\n",
       " 436: 'announce',\n",
       " 437: 'right',\n",
       " 438: 'here',\n",
       " 439: 'heating',\n",
       " 440: 'currency',\n",
       " 441: 'hurt',\n",
       " 442: 'ipo',\n",
       " 443: 'public',\n",
       " 444: 'blame',\n",
       " 445: 'particular',\n",
       " 446: 'negative',\n",
       " 447: 'rival',\n",
       " 448: 'magazine',\n",
       " 449: 'main',\n",
       " 450: 'sharp',\n",
       " 451: 'revision',\n",
       " 452: 'small',\n",
       " 453: 'dvd',\n",
       " 454: 'produce',\n",
       " 455: 'system',\n",
       " 456: 'uncomfortably',\n",
       " 457: 'soon',\n",
       " 458: 'reckson',\n",
       " 459: 'securities',\n",
       " 460: 'unchanged',\n",
       " 461: 'debt',\n",
       " 462: 'speculation',\n",
       " 463: 'banking',\n",
       " 464: 'earlier',\n",
       " 465: 'clear',\n",
       " 466: 'worker',\n",
       " 467: 'compensation',\n",
       " 468: 'action',\n",
       " 469: 'strike',\n",
       " 470: 'effect',\n",
       " 471: 'fresh',\n",
       " 472: 'bond',\n",
       " 473: 'force',\n",
       " 474: 'additional',\n",
       " 475: 'official',\n",
       " 476: 'head',\n",
       " 477: 'correction',\n",
       " 478: 'live',\n",
       " 479: 'american',\n",
       " 480: 'teen',\n",
       " 481: 'hot',\n",
       " 482: 'tivo',\n",
       " 483: 'cable',\n",
       " 484: 'place',\n",
       " 485: 'factory',\n",
       " 486: 'consider',\n",
       " 487: 'potential',\n",
       " 488: 'mean',\n",
       " 489: 'international',\n",
       " 490: 'develop',\n",
       " 491: 'china',\n",
       " 492: 'plug',\n",
       " 493: 'vue',\n",
       " 494: 'advantage',\n",
       " 495: 'recent',\n",
       " 496: 'benchmark',\n",
       " 497: 'import',\n",
       " 498: 'kong',\n",
       " 499: 'vote',\n",
       " 500: 'pound',\n",
       " 501: 'vikings',\n",
       " 502: 'bears',\n",
       " 503: 'regulation',\n",
       " 504: 'thank',\n",
       " 505: 'lot',\n",
       " 506: 'stand',\n",
       " 507: 'giant',\n",
       " 508: 'television',\n",
       " 509: 'account',\n",
       " 510: 'electronics',\n",
       " 511: 'manager',\n",
       " 512: 'package',\n",
       " 513: 'chicago',\n",
       " 514: 'commission',\n",
       " 515: 'conclude',\n",
       " 516: 'internet',\n",
       " 517: 'partner',\n",
       " 518: 'begin',\n",
       " 519: 'warn',\n",
       " 520: 'radio',\n",
       " 521: 'actually',\n",
       " 522: 'london',\n",
       " 523: 'saudi',\n",
       " 524: 'seek',\n",
       " 525: 'alternative',\n",
       " 526: 'gold',\n",
       " 527: 'majority',\n",
       " 528: 'personal',\n",
       " 529: 'situation',\n",
       " 530: 'later',\n",
       " 531: 'thing',\n",
       " 532: 'check',\n",
       " 533: 'war',\n",
       " 534: 'particularly',\n",
       " 535: 'involve',\n",
       " 536: 'court',\n",
       " 537: 'rule',\n",
       " 538: 'americans',\n",
       " 539: 'bear',\n",
       " 540: 'surprise',\n",
       " 541: 'feel',\n",
       " 542: 'ask',\n",
       " 543: 'management',\n",
       " 544: 'engine',\n",
       " 545: 'times',\n",
       " 546: 'mark',\n",
       " 547: 'write',\n",
       " 548: 'federated',\n",
       " 549: 'rest',\n",
       " 550: 'medium',\n",
       " 551: 'customer',\n",
       " 552: 'steep',\n",
       " 553: 'treasury',\n",
       " 554: 'yield',\n",
       " 555: 'condition',\n",
       " 556: 'nokia',\n",
       " 557: 'operate',\n",
       " 558: 'mobile',\n",
       " 559: 'jet',\n",
       " 560: 'compete',\n",
       " 561: 'asset',\n",
       " 562: 'barclays',\n",
       " 563: 'indicator',\n",
       " 564: 'pass',\n",
       " 565: 'tight',\n",
       " 566: 'family',\n",
       " 567: 'player',\n",
       " 568: 'near',\n",
       " 569: 'nfl',\n",
       " 570: 'build',\n",
       " 571: 'pick',\n",
       " 572: 'happen',\n",
       " 573: 'eye',\n",
       " 574: 'subscriber',\n",
       " 575: 'rebound',\n",
       " 576: 'exclude',\n",
       " 577: 'matter',\n",
       " 578: 'unemployment',\n",
       " 579: 'wage',\n",
       " 580: 'development',\n",
       " 581: 'emerge',\n",
       " 582: 'rally',\n",
       " 583: 'finally',\n",
       " 584: 'drive',\n",
       " 585: 'car',\n",
       " 586: 'guidance',\n",
       " 587: 'pengrowth',\n",
       " 588: 'acquisition',\n",
       " 589: 'nikkei',\n",
       " 590: 'standard',\n",
       " 591: 'advance',\n",
       " 592: 'lcd',\n",
       " 593: 'single',\n",
       " 594: 'citigroup',\n",
       " 595: 'series',\n",
       " 596: 'suggest',\n",
       " 597: 'broker',\n",
       " 598: 'tax',\n",
       " 599: 'kerkorian',\n",
       " 600: 'pork',\n",
       " 601: 'disappointing',\n",
       " 602: 'cheesecake',\n",
       " 603: 'mall',\n",
       " 604: 'date',\n",
       " 605: 'traffic',\n",
       " 606: 'option',\n",
       " 607: 'available',\n",
       " 608: 'separate',\n",
       " 609: 'strategy',\n",
       " 610: 'addition',\n",
       " 611: 'best',\n",
       " 612: 'answer',\n",
       " 613: 'shipping',\n",
       " 614: 'popular',\n",
       " 615: 'declare',\n",
       " 616: 'experience',\n",
       " 617: 'return',\n",
       " 618: 'network',\n",
       " 619: 'handle',\n",
       " 620: 'legal',\n",
       " 621: 'black',\n",
       " 622: 'baby',\n",
       " 623: 'win',\n",
       " 624: 'apple',\n",
       " 625: 'room',\n",
       " 626: 'reverse',\n",
       " 627: 'organization',\n",
       " 628: 'prospect',\n",
       " 629: 'yen',\n",
       " 630: 'buyer',\n",
       " 631: 'chain',\n",
       " 632: 'catalogue',\n",
       " 633: 'promise',\n",
       " 634: 'household',\n",
       " 635: 'position',\n",
       " 636: 'confirm',\n",
       " 637: 'information',\n",
       " 638: 'explain',\n",
       " 639: 'law',\n",
       " 640: 'suffer',\n",
       " 641: 'appeal',\n",
       " 642: 'advertising',\n",
       " 643: 'light',\n",
       " 644: 'willing',\n",
       " 645: 'anticipate',\n",
       " 646: 'managing',\n",
       " 647: 'better',\n",
       " 648: 'content',\n",
       " 649: 'cheer',\n",
       " 650: 'google',\n",
       " 651: 'ad',\n",
       " 652: 'san',\n",
       " 653: 'tech',\n",
       " 654: 'manufacture',\n",
       " 655: 'clue',\n",
       " 656: 'comparison',\n",
       " 657: 'view',\n",
       " 658: 'goldman',\n",
       " 659: 'los',\n",
       " 660: 'angeles',\n",
       " 661: 'download',\n",
       " 662: 'dominate',\n",
       " 663: 'death',\n",
       " 664: 'competitive',\n",
       " 665: 'departments',\n",
       " 666: 'realtors',\n",
       " 667: 'lend',\n",
       " 668: 'upside',\n",
       " 669: 'summary',\n",
       " 670: 'preliminary',\n",
       " 671: 'kongs',\n",
       " 672: 'hang',\n",
       " 673: 'seng',\n",
       " 674: 'competitor',\n",
       " 675: 'delay',\n",
       " 676: 'version',\n",
       " 677: 'billionaire',\n",
       " 678: 'realty',\n",
       " 679: 'trust',\n",
       " 680: 'consensus',\n",
       " 681: 'gradually',\n",
       " 682: 'substantial',\n",
       " 683: 'possible',\n",
       " 684: 'process',\n",
       " 685: 'ceo',\n",
       " 686: 'steady',\n",
       " 687: 'asia',\n",
       " 688: 'prove',\n",
       " 689: 'tear',\n",
       " 690: 'washington',\n",
       " 691: 'pretty',\n",
       " 692: 'warning',\n",
       " 693: 'message',\n",
       " 694: 'trim',\n",
       " 695: 'consistent',\n",
       " 696: 'automotive',\n",
       " 697: 'healthy',\n",
       " 698: 'deutsche',\n",
       " 699: 'tillman',\n",
       " 700: 'foundation',\n",
       " 701: 'resource',\n",
       " 702: 'love',\n",
       " 703: 'landing',\n",
       " 704: 'old',\n",
       " 705: 'merrill',\n",
       " 706: 'problem',\n",
       " 707: 'satellite',\n",
       " 708: 'put',\n",
       " 709: 'residential',\n",
       " 710: 'adjustment',\n",
       " 711: 'wrong',\n",
       " 712: 'cause',\n",
       " 713: 'equivalent',\n",
       " 714: 'program',\n",
       " 715: 'ifc',\n",
       " 716: 'transaction',\n",
       " 717: 'south',\n",
       " 718: 'dip',\n",
       " 719: 'blog',\n",
       " 720: 'member',\n",
       " 721: 'saturn',\n",
       " 722: 'wagoner',\n",
       " 723: 'premium',\n",
       " 724: 'companys',\n",
       " 725: 'reduce',\n",
       " 726: 'cautious',\n",
       " 727: 'offset',\n",
       " 728: 'current',\n",
       " 729: 'bolster',\n",
       " 730: 'extend',\n",
       " 731: 'stage',\n",
       " 732: 'country',\n",
       " 733: 'link',\n",
       " 734: 'journal',\n",
       " 735: 'unexpectedly',\n",
       " 736: 'draw',\n",
       " 737: 'change',\n",
       " 738: 'employment',\n",
       " 739: 'recession',\n",
       " 740: 'buyout',\n",
       " 741: 'match',\n",
       " 742: 'fix',\n",
       " 743: 'peak',\n",
       " 744: 'pcrd',\n",
       " 745: 'foreign',\n",
       " 746: 'block',\n",
       " 747: 'costco',\n",
       " 748: 'bit',\n",
       " 749: 'warm',\n",
       " 750: 'heinz',\n",
       " 751: 'dolphins',\n",
       " 752: 'sure',\n",
       " 753: 'inflatable',\n",
       " 754: 'hog',\n",
       " 755: 'dealer',\n",
       " 756: 'borrowing',\n",
       " 757: 'interested',\n",
       " 758: 'depend',\n",
       " 759: 'operating',\n",
       " 760: 'office',\n",
       " 761: 'conduct',\n",
       " 762: 'vice',\n",
       " 763: 'circuit',\n",
       " 764: 'heavy',\n",
       " 765: 'purchase',\n",
       " 766: 'item',\n",
       " 767: 'plasma',\n",
       " 768: 'cell',\n",
       " 769: 'console',\n",
       " 770: 'challenge',\n",
       " 771: 'kind',\n",
       " 772: 'brick',\n",
       " 773: 'join',\n",
       " 774: 'web',\n",
       " 775: 'jump',\n",
       " 776: 'acquire',\n",
       " 777: 'center',\n",
       " 778: 'ups',\n",
       " 779: 'visit',\n",
       " 780: 'plant',\n",
       " 781: 'delivery',\n",
       " 782: 'ebay',\n",
       " 783: 'let',\n",
       " 784: 'plenty',\n",
       " 785: 'trouble',\n",
       " 786: 'yuletide',\n",
       " 787: 'rush',\n",
       " 788: 'computers',\n",
       " 789: 'ipod',\n",
       " 790: 'living',\n",
       " 791: 'root',\n",
       " 792: 'minister',\n",
       " 793: 'slide',\n",
       " 794: 'uncertainty',\n",
       " 795: 'gmt',\n",
       " 796: 'reduction',\n",
       " 797: 'underpin',\n",
       " 798: 'act',\n",
       " 799: 'reporter',\n",
       " 800: 'resume',\n",
       " 801: 'reason',\n",
       " 802: 'largely',\n",
       " 803: 'own',\n",
       " 804: 'respectively',\n",
       " 805: 'penney',\n",
       " 806: 'exception',\n",
       " 807: 'portfolio',\n",
       " 808: 'different',\n",
       " 809: 'seller',\n",
       " 810: 'wish',\n",
       " 811: 'pier',\n",
       " 812: 'upscale',\n",
       " 813: 'kid',\n",
       " 814: 'what',\n",
       " 815: 'youtube',\n",
       " 816: 'certain',\n",
       " 817: 'draizen',\n",
       " 818: 'relationship',\n",
       " 819: 'search',\n",
       " 820: 'thought',\n",
       " 821: 'complete',\n",
       " 822: 'generation',\n",
       " 823: 'francisco',\n",
       " 824: 'rating',\n",
       " 825: 'middle',\n",
       " 826: 'debate',\n",
       " 827: 'digit',\n",
       " 828: 'blue',\n",
       " 829: 'chip',\n",
       " 830: 'sluggish',\n",
       " 831: 'downward',\n",
       " 832: 'final',\n",
       " 833: 'idea',\n",
       " 834: 'certainly',\n",
       " 835: 'throw',\n",
       " 836: 'finish',\n",
       " 837: 'sachs',\n",
       " 838: 'movie',\n",
       " 839: 'studio',\n",
       " 840: 'definition',\n",
       " 841: 'model',\n",
       " 842: 'fight',\n",
       " 843: 'segment',\n",
       " 844: 'anytime',\n",
       " 845: 'trader',\n",
       " 846: 'heel',\n",
       " 847: 'bag',\n",
       " 848: 'slight',\n",
       " 849: 'productivity',\n",
       " 850: 'deliver',\n",
       " 851: 'previously',\n",
       " 852: 'independent',\n",
       " 853: 'shares',\n",
       " 854: 'collateral',\n",
       " 855: 'direction',\n",
       " 856: 'forward',\n",
       " 857: 'possibility',\n",
       " 858: 'monitor',\n",
       " 859: 'lauder',\n",
       " 860: 'wii',\n",
       " 861: 'arm',\n",
       " 862: 'fear',\n",
       " 863: 'reform',\n",
       " 864: 'repeat',\n",
       " 865: 'scenario',\n",
       " 866: 'basis',\n",
       " 867: 'employee',\n",
       " 868: 'maintain',\n",
       " 869: 'reaction',\n",
       " 870: 'wealth',\n",
       " 871: 'monetary',\n",
       " 872: 'ride',\n",
       " 873: 'kill',\n",
       " 874: 'surprised',\n",
       " 875: 'apparently',\n",
       " 876: 'section',\n",
       " 877: 'try',\n",
       " 878: 'fashion',\n",
       " 879: 'style',\n",
       " 880: 'invest',\n",
       " 881: 'stuff',\n",
       " 882: 'location',\n",
       " 883: 'environment',\n",
       " 884: 'yesterday',\n",
       " 885: 'coverage',\n",
       " 886: 'wonder',\n",
       " 887: 'describe',\n",
       " 888: 'decision',\n",
       " 889: 'catch',\n",
       " 890: 'banker',\n",
       " 891: 'name',\n",
       " 892: 'leader',\n",
       " 893: 'provider',\n",
       " 894: 'comcast',\n",
       " 895: 'tivos',\n",
       " 896: 'example',\n",
       " 897: 'ultimately',\n",
       " 898: 'deceleration',\n",
       " 899: 'prepared',\n",
       " 900: 'remark',\n",
       " 901: 'rapidly',\n",
       " 902: 'bet',\n",
       " 903: 'history',\n",
       " 904: 'building',\n",
       " 905: 'builder',\n",
       " 906: 'unsold',\n",
       " 907: 'limited',\n",
       " 908: 'extra',\n",
       " 909: 'banks',\n",
       " 910: 'professor',\n",
       " 911: 'school',\n",
       " 912: 'lynch',\n",
       " 913: 'financing',\n",
       " 914: 'loan',\n",
       " 915: 'finance',\n",
       " 916: 'approve',\n",
       " 917: 'involvement',\n",
       " 918: 'conference',\n",
       " 919: 'double',\n",
       " 920: 'previous',\n",
       " 921: 'heat',\n",
       " 922: 'tend',\n",
       " 923: 'disc',\n",
       " 924: 'motors',\n",
       " 925: 'electric',\n",
       " 926: 'battery',\n",
       " 927: 'toyota',\n",
       " 928: 'north',\n",
       " 929: 'express',\n",
       " 930: 'truck',\n",
       " 931: 'significant',\n",
       " 932: 'clearly',\n",
       " 933: 'word',\n",
       " 934: 'comfort',\n",
       " 935: 'asian',\n",
       " 936: 'taiwans',\n",
       " 937: 'australian',\n",
       " 938: 'approach',\n",
       " 939: 'british',\n",
       " 940: 'familiar',\n",
       " 941: 'top',\n",
       " 942: 'revise',\n",
       " 943: 'mix',\n",
       " 944: 'initial',\n",
       " 945: 'kyodo',\n",
       " 946: 'panel',\n",
       " 947: 'pull',\n",
       " 948: 'samsung',\n",
       " 949: 'attractive',\n",
       " 950: 'tie',\n",
       " 951: 'cash',\n",
       " 952: 'attract',\n",
       " 953: 'broadcast',\n",
       " 954: 'recently',\n",
       " 955: 'pfizers',\n",
       " 956: 'wachovia',\n",
       " 957: 'picture',\n",
       " 958: 'adjust',\n",
       " 959: 'brothers',\n",
       " 960: 'slip',\n",
       " 961: 'analysis',\n",
       " 962: 'occur',\n",
       " 963: 'markets',\n",
       " 964: 'unexpected',\n",
       " 965: 'exxon',\n",
       " 966: 'jobless',\n",
       " 967: 'claim',\n",
       " 968: 'ftse',\n",
       " 969: 'german',\n",
       " 970: 'performance',\n",
       " 971: 'carrier',\n",
       " 972: 'lis',\n",
       " 973: 'father',\n",
       " 974: 'beijing',\n",
       " 975: 'australias',\n",
       " 976: 'instead',\n",
       " 977: 'korea',\n",
       " 978: 'showing',\n",
       " 979: 'barometer',\n",
       " 980: 'export',\n",
       " 981: 'streets',\n",
       " 982: 'cpi',\n",
       " 983: 'kohls',\n",
       " 984: 'range',\n",
       " 985: 'expense',\n",
       " 986: 'raiders',\n",
       " 987: 'pipeline',\n",
       " 988: 'evidence',\n",
       " 989: 'viking',\n",
       " 990: 'agent',\n",
       " 991: 'litigation',\n",
       " 992: 'philips',\n",
       " 993: 'oklahoma',\n",
       " 994: 'corn',\n",
       " 995: 'feed',\n",
       " 996: 'tighten',\n",
       " 997: 'bernard',\n",
       " 998: 'sands',\n",
       " 999: 'exceed',\n",
       " 1000: 'restaurant',\n",
       " ...}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the longest string for padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3565\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(doc.split()) for doc in train_docs1])\n",
    "print(max_length)\n",
    "\n",
    "xtrain_docs = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the one-hot encoded dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xtrain_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary size is the total number of words in our vocabulary, plus one for unknown words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2983"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define vocabulary size (largest integer value)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the neural network model:\n",
    "\n",
    "We use just 1 output node for the classification since we use the sigmoid activivation function which will just return the predicted value.\n",
    "\n",
    "Alternatively, You could create a neural network with two output nodes, one for each sex, and use softmax activation so that the outputs sum to 1.0 and could be interpreted as probabilities. For example if output node 0 is male and output node 1 is female, and the neural network output values are 0.75 and 0.25, you’d conclude the person is a male.\n",
    "\n",
    "On the other hand, you could create a neural network with just one output node, and use log-sigmoid activation so that the single output, which will be between 0 and 1, represents the probability of just one of the two classes (say, male). So if the output was 0.44, you’d infer the probability of male is 0.44 and therefore the probability of female is 0.56 and conclude the person is female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-9ab0002a7ecb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                 raise ValueError('Layer ' + self.name + ' was called with '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \"\"\"\n\u001b[1;32m--> 695\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m    697\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_TensorLike\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_length=vocab_size, output_dim=100, input_length=max_length))\n",
    "model.add(LSTM(kernel_size=8, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6242a9f9be4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(xtrain_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(xtrain_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
